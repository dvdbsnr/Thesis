% Chapter 2: Preliminaries
% Contains:
%   Weak convergence
%   Vague convergence
%   etc.

\chapter{Preliminaries} \label{C: preliminaries}
\fxnote{Update title.} 

\section{Function spaces $C$ and $D$}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: On weak convergence
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Weak convergence of probability measures}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: On weak convergence
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fxnote{Introductory text.}

\fxnote{Definition weak convergence}
This section will probably move to a preliminary chapter.
\begin{definition}[Weak convergence]
	Let $S$ be a metric space and $\mathcal{S}$ it's class of Borel sets.
	Let $P, P_1, P_2, \dots$ be probability measures on defined on $S$.
	We say $P_n$ converges weakly to $P$, $P_n \Rightarrow P$, if
	\begin{equation} 
	\int_S fdP_n \xrightarrow{n \rightarrow \infty} \int_S fdP
	\end{equation}
	holds for all continuous, bounded functions $f: S \rightarrow \Real$.
\end{definition}

This definition now applies to convergence in distribution of random variables as follows:
Let $X, X_1, X_2, \dots$ be random variables on some probability space $S$.
Let $P, P_1, P_2, \dots$ be the corresponding distributions. 

\begin{definition}[Tightness] \label{D: Tightness}
	Inhalt...
\end{definition}

\begin{definition}[Relative compactness] \label{D: Rel Compactness}
	Inhalt...
\end{definition}

\begin{theorem}[Prohorov's theorem] \label{T: Prohorov}
	Let $P_n$ be a series of probability measures on some metric space $S$. If $P_n$ is tight, then it is relatively compact.
\end{theorem}



We will prove weak convergence by showing that
\begin{equation}
\Exp{ f(\bar{Z}^t_n, \bar{N}_n) } \longrightarrow \Exp{ f(W^t, N) }
\end{equation}
as $n \rightarrow \infty$, 
for all continuous, bounded functions 
$f: D^2 \rightarrow \Real$.

We state the theorem here, without proof, as it appears in \cite[Theorem 1.4, p.339 f.]{Ethier.2005},
omitting one of two equivalent conditions and all references to higher dimensional processes,
in order to focus on the one-dimensional case we will need for our proof.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Central limit theorem for martingales: Statement
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{theorem}[Central limit theorem for martingales] \label{T: functional CLT martingales}
	Let $\{\Fn{t}\}$ be a filtration and $M_n$ a $\{\Fn{t}\}$-local martingale with sample paths in $D_{\Real}[0,\infty)$ and $\Mn{0}=0$.
	Let $B_n$ be a process with sample paths in $D_{\Real}[0,\infty)$, increasing in $t$, such that $M_n^2 - B_n$ is an $\{\Fn{t}\}$-local martingale.
	
	Let the following conditions hold:
	For each $T>0$,
	\begin{equation} \label{E: cond1 CLT}
	\lim_{n->\infty} \ExpBig{
		\sup_{t \leq T} | \Bn{t} - \Bn{t-}|
	} = 0,
	\end{equation}
	\begin{equation} \label{E: cond2 CLT}
	\lim_{n->\infty} \ExpBig{
		\sup_{t \leq T} | \Mn{t} - \Mn{t-}|^2
	} = 0,
	\end{equation}
	and with $c(t)$ a continuous, increasing function on $[0, \infty)$, $c(0) = 0$, let
	\begin{equation} \label{E: cond3 CLT}
	\Bn{t} \longrightarrow_p c(t).
	\end{equation}
	Then $M_n \longrightarrow_d X$ where $X$ is a process with sample paths in $C_{\Real}[0,\infty)$ and independent Gaussian increments.
\end{theorem}



\section{Counting processes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Counting processes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Girsanov Theorem
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We conclude this chapter by introducing Girsanovs Theorem,
which will enable us to prove certain properties of the Brownian motion with drift.
We state the theorem as it appears in \cite[Theorem 4.2.2, p.66]{Lamberton.2000}.

\begin{theorem}[Girsanov] \label{T: Girsanov}
	Let $(W(s))_{0 \leq s \leq T}$ be a Brownian motion on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$.
	Let $(\Theta(s))_{0 \leq s \leq T}$ be an adapted process satisfying
	\begin{equation} \label{E: Girsanov cond Theta}
	\int_{0}^{T} \Theta^2(u)du < \infty.
	\end{equation}
	Define
	\begin{align}
	\tilde{W}(s) &:= W(s) + \int_0^s \Theta(u)du, \label{E: Girsanov def W tilde} \\ 
	X(s) &:= \exp \left\{ -\int_{0}^{s} \Theta(u) dW(u) - \frac{1}{2} \int_0^s \Theta^2(u)du \right\}. \label{E: Girsanov def X}
	\end{align}
	If $X(s)$ a martingale, that is $\Exp{X(s)} = \Exp{X(0)} = 1$ for all $s$,
	the measure $\mathbb{Q}$, defined by
	\begin{equation} \label{E: Girsanov def P tilde}
	\tilde{\mathbb{P}}(A) := \int_A X(\omega) d\mathbb{P}(\omega), \; \text{for all} \; A \in \mathcal{F},
	\end{equation}
	is a probability measure under which the process 
	$(\tilde{W}(s))_{0 \leq s \leq T}$
	is a Brownian motion.
\end{theorem}

By \cite[Remark 4.2.3, p.66]{Lamberton.2000}, a sufficient condition for $X(t)$ to be a martingale is the so-called Novikov-condition
\begin{equation} \label{E: Novikov}
\ExpBig{ \exp \left( \frac{1}{2} \int_{0}^{T} \Theta^2(u)du \right) } < \infty.
\end{equation}

We can apply this Theorem to the Brownian motion with drift $W^t$ as follows:
Recall the definition
\begin{equation}
\Wt(s) = W(s) + ts - \frac{1}{2} s^2 = W(s) + \int_0^s (t-u)du.
\end{equation}
For $T<\infty$, $\Theta(u) := t-u$ satisfies \eqref{E: Novikov},
therefore $X(t)$, as defined in \eqref{E: Girsanov def X}, is a martingale and
$\Wt$ is a standard Brownian motion under the probability measure $\tilde{\mathbb{P}}$ defined in \eqref{E: Girsanov def P tilde}.
Since $X(s) > 0$ almost surely for all $s$, the probability measures $\mathbb{P}$ and $\tilde{\mathbb{P}}$ agree which sets have probability zero:
\begin{equation} \label{E: P0 = Q0}
\mathbb{P}(A) = 0 \iff \tilde{\mathbb{P}}(A) = 0, \; \text{for all} \; A \in \mathcal{F}.
\end{equation}
Properties holding with probability $1$ or $0$ for a standard Brownian motion will hold with probability $1$ or $0$, respectively,
for $\Wt$ under $\tilde{\mathbb{P}}$ and hence under the original measure $\mathbb{P}$.

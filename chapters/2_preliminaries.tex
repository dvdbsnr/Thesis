% Chapter 2: Preliminaries
% Contains:
%   Weak convergence
%   Vague convergence
%   etc.

\chapter{Preliminaries} \label{C: preliminaries}
\fxnote{Update title.} 

\section{Weak convergence of probability measures} \label{S: weak convergence}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: On weak convergence
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The central notion of this thesis is the convergence in distribution of random variables in general metric spaces.
The results presented in this section and the next will be of special importance in the proof of Theorem~\ref{T: Joint Convergence}
in Chapter~\ref{C: surplus edges}.

\begin{definition}[Weak convergence, {\cite[p.7]{Billingsley.1999}}] \label{D: weak convergence}
	Let $\mu_n$, $\mu$ be measures on a metric space $S$ with associated \Bosi $\mathcal{S} = \Bo(S)$.
	
	Denote by $\Cb(S)$ the space of bounded, continuous functions $f: S \rightarrow \Real$.
	
	We say $\mu_n$ converges weakly to $\mu$, $\mu_n \Rightarrow \mu$, if
	\begin{equation}
		\int_S fd\mu_n \rightarrow \int_s fd\mu
	\end{equation}
	as $n \rightarrow \infty$ for all $f \in \Cb(S)$.
\end{definition}

We say a random variable $X$ in $(S, \mathcal{S})$, 
defined on a probability space $\ProbSpace$,
has distribution or law $P$ if
\begin{equation}
	P(A) := \Prob(X \in A)
\end{equation}
for all $A \in \mathcal{S}$.

For a series of random variables in the same metric space to converge in distribution 
does not require them to be defined on the same probability space.
Let $X_n$, $X$ be random variables in a metric space $(S, \mathcal{S})$,
\begin{equation}
\begin{aligned}
	X: \ProbSpace &\rightarrow (S, \mathcal{S}), \\
	X_i: (\Omega_i, \SigmaAlgebra_i, \Prob_i) &\rightarrow (S, \mathcal{S}),
\end{aligned}
\end{equation}
with associated distributions $P_n$, $P$.
Now $X_n$ converges in distribution to $X$, $X_n \rightarrow_d X$,
if their distribution measures converge weakly, $P_n \Rightarrow P$.

The main goal of this chapter is now to find necessary and sufficient conditions
for the convergence in distribution of a given sequence of random variables 
or equivalently the weak convergence of their distribution measures.

A first useful reference provides the so-called Portmanteau theorem.
\begin{theorem}[Portmanteau, {\cite[Theorem 2.1, p.16]{Billingsley.1999}}] \label{T: portmanteau weak}
	Let $P_n$, $P$ be probability measures on $(S, \mathcal{S})$.
	The following conditions are equivalent:
	\begin{enumerate}
		\item $P_n \Rightarrow P$,
		\item $\int_S fdP_n \rightarrow \int_S fdP$ for all $f \in \Cb(S)$,
		\item $\limsup_n P_n(F) \leq P(F)$ for all closed $F$,
		\item $\liminf_n P_n(G) \geq P(G)$ for all open $G$,
		\item $P_n(A) \rightarrow P(A)$ for all $A$ with $P(\partial A) = 0$.
	\end{enumerate}
\end{theorem}

A powerful tool to prove weak convergence of measures is relative compactness.

\begin{definition}[Relative compactness, {\cite[p.57]{Billingsley.1999}}] \label{D: rel compactness}
	Let $\Pi$ be a family of probability measures on $(S, \mathcal{S})$.
	We call $\Pi$ \emph{relatively compact} if for every sequence in $\Pi$ there exists a convergent subsequence.
	That is, for all sequences $\{P_n\} \subset \Pi$ there exists $\{P_{n_i} \} \subset \Pi$
	and a probability measure $Q$ on $(S, \mathcal{S})$, not necessarily on $\Pi$,
	such that $P_{n_i} \Rightarrow_i Q$.
	
	We call a sequence of probability measures $\{P_n\}$ relatively compact if
	for every subsequence $\{P_{n_i}\}$ there exists a further subsequence
	$\{P_{n_{i_k}}\}$ and a probability measure $Q$ such that
	$P_{n_{i_k}} \Rightarrow_k Q$.
\end{definition}

For function spaces, knowing that a sequence of functions is relatively compact
provides us with a powerful tool to prove convergence in distribution.

\begin{definition}[Finite dimensional distributions, {\cite{Aldous.1997}}] \label{D: fidi distributions}
	\fxfatal{Add real reference here.}
	Let $X: \Omega \times \Rplus \rightarrow \mathbb{X}$ be a stochastic process with distribution $P$
	For $t_1, \dots, t_k \in \Rplus$ we denote by \emph{finite-dimensional distributions} of $X$ 
	the push forward measures 
	\begin{equation}
		P\pi^{-1}_{t_1, \dots, t_k}(A) := \Prob\{ X(t_1) \in A_1, \dots, X(t_k) \in A_k \}
	\end{equation}
	for $A = A_1 \times \dots \times A_k \in \mathbb{X}^k$.
\end{definition}

Now consider a relatively compact sequence of stochastic processes $\{X_n\}$,
with distributions $\{P_n\}$,
and a stochastic process $X$ with distribution $P$,
such that
\begin{equation}
	P_n\pi^{-1}_{t_1, \dots, t_k} \Rightarrow P\pi^{-1}_{t_1, \dots, t_k}
\end{equation}
for all $k$ and $t_1, \dots, t_k \in \Rplus$.
Since $\{P_n\}$ is relatively compact,
we know that every subsequence contains a further subsequence converging to some probability measure $Q$.
It can be shown that the convergence of finite-dimensional distributions implies that all of these
limit measure are in fact $P$,
which in turn proves $P_n \Rightarrow P$. For details see \cite[p.57]{Billingsley.1999}.

If we can prove a series of probability measure to converge in finite-dimensional distributions to some
limit measure we therefore only need to show relative compactness of the series
for the convergence in distribution to hold.

Relative compactness is closely linked to another property of series of measures, tightness.

We call a measure $\mu$ on a metric space tight,
if for all $\epsilon > 0$ there exists a compact $K$ such that
\begin{equation}
	\mu(K^c) < \epsilon.
\end{equation}

This carries over to families of probability measures as follows:

\begin{definition}[Tightness of families of probability measures, {\cite[p.59]{Billingsley.1999}}] \label{D: tightness}
	A family $\Pi$ of probability measures on a metric space $(S, \mathcal{S})$ is \emph{tight} 
	if for every $\epsilon > 0$ there exists a compact $K \subset S$
	such that $P(K) > 1 - \epsilon$
	for all $P \in \Pi$.	
\end{definition}

The last main result of this section now provides a link between tightness and relative compactness
and therefore an effective means of proving convergence in distribution.

\begin{theorem}[Prohorov's theorem, {\cite[Theorem 5.1, p.59]{Billingsley.1999}}] \label{T: Prohorov}
	Let $P_n$ be a series of probability measures on a metric space $(S, \mathcal{S})$. 
	If $P_n$ is tight, it is relatively compact.
\end{theorem}

We summarize this theorem and our considerations above in the following lemma.

\begin{lemma} \label{L: tightness and fidi}
	Let $X, X_n$ be stochastic processes with distributions $P, P_n$.
	If $\{X_n\}$  is tight and
	\begin{equation*}
		P_n\pi^{-1}_{t_1, \dots, t_k} \Rightarrow P\pi^{-1}_{t_1, \dots, t_k},
	\end{equation*}
	for all $k$ and $t_1, \dots, t_k \in \Rplus$,
	then $X_n \Rightarrow X$.
\end{lemma}


\section{The space $\DT$} \label{S: space DT}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: The space D
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The coming chapters will mainly deal with two types of stochastic processes:
Brownian motion and so-called \cadlag-processes.
This section will deal with the issue of proving tightness and thus convergence for the latter.

\begin{definition}[The space $\DT$, {\cite[p.121]{Billingsley.1999}}] \label{D: DT}
	We call a function $f: I \rightarrow \Real$, $I \subseteq \Rplus$, \emph{\cadlag},
	if
	\begin{enumerate}
		\item for $t \in I$, $f(t+) = \lim_{s \downarrow t}f(s)$ exists and $f(t) = f(t+)$,
		\item for $t \in I$, $f(t-) = \lim_{s \uparrow t}f(s)$ exists.
	\end{enumerate}
	These functions are right-continuous possess left limits everywhere (continue à droite, limite à gauche).
	
	We denote by $\DT$ the space of \cadlag-functions on $I = [0,T]$.
\end{definition}

Considering topology and convergence on $\DT$, 
we quickly observe that the known notion of distance known in $C(I)$,
the space of continuous functions on $I$,
where
\begin{equation}
	f_n \rightarrow f \iff \sup_{t \in I} |f_n(t) - f(t)| \rightarrow 0,
\end{equation}
is not sufficient for $\DT$.
Consider the functions
\begin{equation}
	\begin{aligned}
	f_n(t) &= 
		\begin{cases} 
		0 & t < x_n, \\
		1 & t \geq x_n, 
		\end{cases} \\
	f(t) &= 
		\begin{cases} 
		0 & t < x, \\
		1 & t \geq x.
		\end{cases} \\
	\end{aligned}
\end{equation}
For $x_n \rightarrow x$ we would expect $f_n$ to converge to $f$,
however $\sup_{t \in I}|f_n(t) - f(t)| = 1$ whenever $x_n \neq x$.

Thinking of the previous convergence as allowing shifts on the y-axis,
we need a convergence that additionally allows shifts on the x-axis.

\begin{definition}[Skorohod metric, {\cite[p.124]{Billingsley.1999}}] \label{D: skorohod}
	Denote by $\Lambda$ the class of strictly increasing, continuous mappings from $[0,T]$ onto itself.
	
	For $x, y \in \DT$, define the \emph{Skorohod metric} $d(x,y)$ as the infimum of all $\epsilon > 0$ 
	for which exists a $\lambda \in \Lambda$ such that
	\begin{enumerate}
		\item $\sup_{t \in [0,T]}|\lambda (t) - t| = \sup_{t \in [0,T]}|t - \lambda^{-1}(t)| < \epsilon$,
		\item  $\sup_{t \in [0,T]}|x(\lambda (t)) - y(t)| = \sup_{t \in [0,T]}|x(t) - y(\lambda^{-1}(t))| < \epsilon$.
	\end{enumerate}
	And writing $\norm{x}_T = \sup_{t \in [0,T]}|x(t)|$ we can provide a more compact form:
	\begin{equation}
		d(x,y) = \inf_{\lambda \in \Lambda}\{ \norm{\lambda - I}_T \vee \norm{x - y(\lambda)}_T \},
	\end{equation}
	where $I:[0,T] \rightarrow [0,T]$ is the identity map.
\end{definition}

\begin{definition}[Modulus of continuity, {\cite[p.122]{Billingsley.1999}}] \label{D: modulus of continuity}
	A set $\{t_i\}$, where $ 0 = t_0 < t_1 < \dots < t_k = T $,
	is called \emph{$\delta$-sparse} if $\min_{1\leq i \leq k} (t_i - t_{i-1}) > \delta$.
	
	For $0 < \delta < 1$ and $x \in \DT$, define the \emph{modulus of continuity} by
	\begin{equation*}
		w_x'(\delta) := \inf_{\{t_i\}} \max_{1\leq i \leq k} w_x[t_{i-1}, t_i),
	\end{equation*}
	where the infimum extends over all $\delta$-sparse sets $\{t_i\}$ and
	\begin{equation*}
		w_x(I) := \sup_{s,t \in I}|x(s)  -x(t)|.
	\end{equation*}
\end{definition}

The Arzelà-Ascoli theorem, see \cite[Theorem 7.2, p.82]{Billingsley.1999},
provides a complete characterisation of relatively compact sets in $\CT$.
We are now ready to present a $\DT$-equivalent.

\begin{theorem}[Arzelà-Ascoli in $\DT$, {\cite[Theorem 12.3, p.130]{Billingsley.1999}}] \label{T: AA in DT}
	A necessary and sufficient condition for a set $A$ to be relatively compact in the Skorohod toplogy is that
	\begin{enumerate}
		\item $\sup_{x \in A} \norm{x}_T < \infty$,
		\item $\lim_{\delta \rightarrow 0} \sup_{x \in A} w'_x(\delta) = 0$.
	\end{enumerate}
\end{theorem}


\section{Point processes} \label{S: point processes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Point processes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In Chapter~\ref{C: convergence} we will finish the proof of Theorem~\ref{T: Main}
by considering excursions of the Brownian motion as two-dimensional point processes
on the positive real line.
This section will provide an overview of the needed theory.

\begin{definition}[Point process, {\cite[p.123]{Resnick.2008}}] \label{D: point process}
	Let $S$ be a locally compact second countable Hausdorff space
	and $\Bo(S)$ its \Bosi.
	Let $\{x_i, i \geq 1\}$ be a collection of points of $S$.
	Let
	\begin{equation}
		\mu := \sum_{i \geq 1} \delta_{x_i},
	\end{equation}
	with $\delta_x$ the Dirac measure of $x \in S$,
	be locally compact, that is, 
	if $C \in \Bo(S)$ is compact then $\mu(C) < \infty$.
	Then $\mu$ is a \emph{point measure} on $E$.
	
	Denote by $M_p(S)$ the space of all point measures on $E$
	and let $\mathscr{M}_p(S)$ be the smallest $\sigma$-algebra containing all sets of the form
	\begin{equation*}
		\{ m \in M_p(S) \cond m(A) \in B \}
	\end{equation*}
	for some $A \in \Bo(S)$ and $B \in \Bo(\Rplus)$.
	
	A \emph{point process} $N$ is a measurable map from a probability space
	$\ProbSpace$ into $(M_p(S), \mathscr{M}_p(S))$.
\end{definition}

For all coming observations, we will take $\Rplus$ as the underlying Hausdorff space with its \Bosi~$\Bo = \Bo(\Rplus)$.

\begin{definition}[Poisson point process, {\cite[p.127, p.130]{Resnick.2008}}] \label{D: poisson process}
	We call a point process $N$ a \emph{Poisson point process} or \emph{Poisson process},
	if
	\begin{enumerate}
		\item for all disjoint sets $A_1, A_2, \dots, A_n \in \Bo$
			the random variables $N(A_1), N(A_2), \dots, N(A_n)$ are independent and
		\item for all $A \in \Bo$, $N(A)$ has Poisson distribution $\Poisson(\gamma)$,
			\begin{equation*}
				\Prob(N(A) = k) = \frac{\gamma^k}{k!}\exp(-\gamma)
			\end{equation*}
			where $\gamma = \gamma(A) \in [0, \infty]$ is the \emph{mean measure} or \emph{intensity} of $N$,
			defined by
			\begin{equation}
				\gamma(A) = \Exp{ N(A) }.
			\end{equation}
	\end{enumerate}
	The mean measure is often given in terms of a \emph{rate} or \emph{conditional intenstiy} $\lambda$ by
	\begin{equation}
		\gamma(A) = \int_A \lambda(t)dt.
	\end{equation}
	We can interpret this conditional intensity as
	\begin{equation}
		\lambda(t)dt \approx \Exp{ N(dt) \cond \F{t} } ,
	\end{equation}
	where $\F{t}$ contains the history of the counting process thus far.
\end{definition}

\begin{definition}[Simple point process, {\cite[p.124]{Resnick.2008}}] \label{D: simple point process}
	A point process $N$ on $\Rplus$ is called \emph{simple} if 
	\begin{equation}
		\Prob( N({x}) > 1 ) = 0
	\end{equation}
	for all $x \in \Rplus$.
\end{definition}

By \cite[Remark 2.1, p.34]{Haenggi.2013} a Poisson point process is simple if and only if
its mean measure $\gamma$ has no discrete component,
that is $\gamma(x) = 0$ for all $x \in \Rplus$.

Given a simple point process, we can interpret its conditional intensity on an infinitesimal interval $[t, t+dt]$ as follows:
Since points of $N$ do not coincide, we can expect $N$ to have either one or no points in $[t, t+dt]$.
Therefore
\begin{equation}
\begin{aligned}
\lambda(t)dt 
&= \Exp{ N([t, t+dt]) | \F{t} } \\
&= \Prob( \text{$N$ has a point in $[t, t+dt]$} \cond \F{t} ),
\end{aligned}
\end{equation}
where $\F{t-}$ denotes the history of $N$ up to, but not including, $t$.
For a rigorous treatment of the conditional intensity, see \cite[p.231ff.]{Daley.2003} and \cite[Chapter 14]{Daley.2008}.

The idea of the conditional intensity estimating the mean number of jumps of a counting process
is made more clear in the following lemma.

\begin{lemma}[Martingale decomposition of a counting process, {\cite[Lemma 7.2.V, p.241]{Daley.2003}}]
	Let $N(t)$, $0 \leq t < \infty$, be a counting process adapted on the history $\F{t}$
	with conditional intensity $\lambda(t)$.
	Let
	\begin{math}
		\gamma(t) = \int_0^t \lambda(t)dt.
	\end{math}
	Then the process $M(t) = N(t) - \gamma(t)$ is an $\F{t}$-martingale.
\end{lemma}

In order to talk reasonably about convergence of point processes,
we first need to introduce a topology on the space of point measures.
The \emph{vague topology} is similar to the one generated by the weak convergence in Section~\ref{S: weak convergence}.
When trying to apply weak convergence to point measures we run into a problem,
since a point measure $\mu = \sum_{i \geq 1} \delta_{x_i}$ may contain an infinite number of points on $\Rplus$
and therefore
\begin{equation*}
	\int_{\Rplus} fd\mu = \sum_{i \geq 1} f(x_i) = \infty
\end{equation*}
for certain $f \in \Cb(\Rplus)$, which makes a discussion of convergence in $\Real$ of the integrals unreasonable.

To counter this, we define a new type of convergence, 
in which the integrals only have to converge for functions with compact support.

\begin{definition}[Vague convergence, {\cite[p.140]{Resnick.2008}}] \label{D: vague convergence}
	Let $\CK(E)$ be the space of continuous real valued functions ona Hausdorff space $E$ with compact support,
	meaning there exists a compact set $K \in \Bo(E)$ such that $f(x) = 0$ for all $x \notin K$.
	
	Let $\mu, \mu_1, \mu_2, \dots$ be point measures on  $E$.
	We say $\mu_n$ \emph{converge vaguely} to $\mu$, $\mu_n \rightarrow_v \mu$, if
	\begin{equation}
		\int_{\Rplus} fd\mu_n \xrightarrow{n \rightarrow \infty} \int_{\Rplus} fd\mu
	\end{equation}
	for all $f \in \CK(\Rplus)$.
\end{definition}

Theorem~\ref{T: portmanteau weak} gave necessary and sufficient conditions for weak convergence of measures,
the following lemma may be seen as an equivalent Portmanteau Theorem in the sense of vague convergence.

\begin{lemma}[Equivalent conditions for vague convergence, {\cite[Proposition 3.12, p.142]{Resnick.2008}}] \label{L: portmanteau vague}
	Let $\mu, \mu_1, \mu_2, \dots$ be point measures on a Hausdorff space $E$.
	The following are equivalent:
	\begin{enumerate}
		\item $\mu_n \rightarrow_v \mu$,
		\item $\mu_n(B) \rightarrow \mu(B)$ for all relatively compact (i.e. with compact closure) $B$ 
			for which $\mu(\partial(B)) = 0$.
		\item $\limsup_n \mu_n(K) \leq \mu(K)$ and $\liminf_n \mu_n(G) \geq \mu(G)$
			for all compact $K$ and all open, relatively compact $G$.
	\end{enumerate}
\end{lemma}

Since point measures are uniquely defined by the points on their underlying space they're describing,
we would expect our idea of convergence to imply some kind of convergence of points on $E$.
In fact, as the next lemma shows, vague convergence does imply a pointwise convergence in $E$.

\begin{lemma}[Pointwise convergence, {\cite[Proposition 3.13, p.144]{Resnick.2008}}] \label{L: pointwise convergence}
	Let $\mu, \mu_1, \mu_2, \dots$ be point measures on $E$ and $\mu_n \rightarrow_v \mu$.
	For compact $K$ with $\mu(\partial K) = 0$ and $n \geq N(K)$
	there exist a labelling of points of $\mu_n$ and $\mu$ in $K$ such that
	\begin{equation}
	\begin{aligned}
		\mu_n(\cdot \cap K) &= \sum_{i=1}^{M} \delta_{x_i^{(n)}}, \\
		\mu(\cdot \cap K) &= \sum_{i=1}^{M} \delta_{x_i},
	\end{aligned}
	\end{equation}
	and in $E^M$
	\begin{equation}
		( x_i^{(n)}, 1 \leq i \leq M ) \xrightarrow{n \rightarrow \infty}
		( x_i, 1 \leq i \leq M  ) 
	\end{equation}
	in the sense of componentwise convergence.
\end{lemma}


\section{On Brownian motion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: On Brownian motion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the course of this thesis we will require two further results on Brownian motion.
First we introduce the central limit theorem for martingales,
which provides us with a means to identify convergence of a martingale to Brownian motion.
It will be used in the proof of Theorem~\ref{T: Z -> W} in Chapter~\ref{C: bf-walk}.

We state the theorem here as it appears in \cite[Theorem 1.4, p.339 f.]{Ethier.2005},
omitting one of two equivalent conditions and all references to higher dimensional processes,
in order to focus on the one-dimensional case we will need for our proof.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Central limit theorem for martingales: Statement
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{theorem}[Central limit theorem for martingales] \label{T: functional CLT martingales}
	Let $\{\Fn{s}\}$ be a filtration and $M_n$ a $\{\Fn{s}\}$-local martingale with sample paths in $D_{\Real}[0,\infty)$ and $M_n(0)=0$.
	Let $A_n$ be a process with sample paths in $D_{\Real}[0,\infty)$, increasing in $s$, such that $M_n^2 - A_n$ is an $\{\Fn{s}\}$-local martingale.
	
	Let the following conditions hold:
	For each $T>0$,
	\begin{equation} \label{E: cond1 CLT}
	\lim_{n->\infty} \ExpBig{
		\sup_{s \leq T} | A_n(s) - A_n(s-)|
	} = 0,
	\end{equation}
	\begin{equation} \label{E: cond2 CLT}
	\lim_{n->\infty} \ExpBig{
		\sup_{s \leq T} | M_n(s) - M_n(s-)|^2
	} = 0,
	\end{equation}
	and with $c(s)$ a continuous, increasing function on $[0, \infty)$, $c(0) = 0$, let
	\begin{equation} \label{E: cond3 CLT}
	A_n(s) \longrightarrow_p c(s).
	\end{equation}
	Then $M_n \longrightarrow_d X$ where $X$ is a process with sample paths in $C_{\Real}[0,\infty)$ and independent Gaussian increments.
\end{theorem}


We conclude this preliminary chapter by presenting the Girsanov theorem,
which will enable us to deduce certain properties of the Brownian motion with drift
and prove Lemma~\ref{L: Lemma 8} in Chapter~\ref{C: convergence}.

\begin{theorem}[Girsanov theorem, {\cite[Theorem 4.2.2, p.66]{Lamberton.2000}}] \label{T: Girsanov}
	Let $(W(s))_{0 \leq s \leq T}$ be a standard Brownian motion on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$.
	Let $(\Theta(s))_{0 \leq s \leq T}$ be an adapted process satisfying
	\begin{equation} \label{E: Girsanov cond Theta}
	\int_{0}^{T} \Theta^2(u)du < \infty.
	\end{equation}
	Define
	\begin{align}
	\tilde{W}(s) &:= W(s) + \int_0^s \Theta(u)du, \label{E: Girsanov def W tilde} \\ 
	X(s) &:= \exp \left\{ -\int_{0}^{s} \Theta(u) dW(u) - \frac{1}{2} \int_0^s \Theta^2(u)du \right\}. \label{E: Girsanov def X}
	\end{align}
	If $X(s)$ a martingale, that is $\Exp{X(s)} = \Exp{X(0)} = 1$ for all $s$,
	the measure $\mathbb{Q}$ defined by
	\begin{equation} \label{E: Girsanov def P tilde}
	\tilde{\mathbb{P}}(A) := \int_A X(\omega) d\mathbb{P}(\omega), \; \text{for all} \; A \in \mathcal{F}
	\end{equation}
	is a probability measure under which the process 
	$(\tilde{W}(s))_{0 \leq s \leq T}$
	is a standard Brownian motion.
\end{theorem}

By \cite[Remark 4.2.3, p.66]{Lamberton.2000}, a sufficient condition for $X(t)$ to be a martingale is the so-called Novikov-condition
\begin{equation} \label{E: Novikov}
\ExpBig{ \exp \left( \frac{1}{2} \int_{0}^{T} \Theta^2(u)du \right) } < \infty.
\end{equation}

We can apply this Theorem to the Brownian motion with drift $W^t$ as follows:
Recall the definition
\begin{equation}
\Wt(s) = W(s) + ts - \frac{1}{2} s^2 = W(s) + \int_0^s (t-u)du.
\end{equation}
For $T<\infty$, $\Theta(u) := t-u$ satisfies \eqref{E: Novikov},
therefore $X(s)$, as defined in \eqref{E: Girsanov def X}, is a martingale and
$\Wt$ is a standard Brownian motion under the probability measure $\tilde{\mathbb{P}}$ defined in \eqref{E: Girsanov def P tilde}.
Since $X(s) > 0$ almost surely for all $s$, 
the probability measures $\mathbb{P}$ and $\tilde{\mathbb{P}}$ agree which events happen almost surely or almost never,
\begin{equation} \label{E: P0 = Q0}
\begin{aligned}
\mathbb{P}(A) = 0 &\iff \tilde{\mathbb{P}}(A) = 0, \\
\mathbb{P}(A) = 1 &\iff \tilde{\mathbb{P}}(A) = 1,
\end{aligned}
\end{equation}
for all $A \in \mathcal{F}$.

When trying to prove that certain properties hold for $\Wt$ under $\mathbb{P}$ almost surely,
it suffices to prove these properties holding for a standard Brownian motion almost surely.
Since $\Wt$ is a standard Brownian motion under $\tilde{\mathbb{P}}$ we can apply \eqref{E: P0 = Q0}
to carry this realization over to $\Wt$ under $\mathbb{P}$.

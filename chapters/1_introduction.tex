% Chapter 1: Introduction
% Contains:
%   An introduction to random graph theory
%   Basic results on the size of random graph components
%   Basic results on the critical window
%   The main theorem:
%      Motivation
%      The Brownian motion
%      Complete statement
%   Overview of coming proof

\chapter{Introduction}
\fxnote{Update title.}

The study of randomly generated graphs started in 1959,
when Paul Erdös and Alfréd Rényis paper "On random graphs", \cite{Erdos.1959}
and Edgar Gilberts paper "Random graphs", \cite{Gilbert.1959},
introduced what is now known as the \emph{Erdös-Rényi model} of random graphs.
In this model, all vertices conect to each other with equal probabilities,
an assumption that is not necessarily present in other random graph models that followed,
like \emph{preferential attachment} or the inhomogeneous Erdös-Rényi model.

Starting with the original papers,
the examination of sizes of connected components in such graphs was of great interest.
A milestone in this study provided David Aldous 1997 paper 
"Brownian excursions, critical random graphs and the multiplicative coalescent", \cite{Aldous.1997}.
This thesis will provide an overview of the state of the research on component sizes in the so-called
critical Erdös-Rényi random graph and provide an in-depth proof of the first results of this paper.
If no other reference is given, each result (or an equivalent thereof) can be found in Chapters 1 and 2 of \cite{Aldous.1997}.


\section{The Erdös-Rényi random graph}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: The Erdös-Rényi random graph
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In their paper, Erdös and Rényi proposed a model of random graph that is now known as the Erdös-Rényi random graph.
There are several ways to construct this random graph which we will briefly introduce,
starting with the historic models used in this first paper 
and continuing with the equivalent model which provides the basis for Aldous' paper and consequently this thesis.

We denote by $G_{n,M}$ the set of graphs on $n$ vertices with $M$ edges that are
\begin{enumerate}
	\item undirected,
	\item without slings, i.e. there is no edge $(v,v)$ for some vertex $v$,
	\item without parallel edges, i.e. there can be at most one edge $(v_1, v_2)$ for each pair of vertices.
\end{enumerate}
A graph in $G_{n,M}$ can be constructed by choosing $M$ out of the $\binom{n}{2}$ possible edges between the vertices,
which leads to a total number of graphs
\begin{equation}
	|G_{n,M}| = \binom{\binom{n}{2}}{M}.
\end{equation}
The Erdös-Rényi random graph $\Gcal(n, M)$ is now obtained by choosing one element of $G_{n,M}$ at random
with equal probability for each graph, where the number of edges is usually dependent on the number of vertices, $M = M(n)$.

An equivalent definition provides the following process:
Starting with a graph on $n$ vertices with $0$ edges at time $t=1$, 
pick one of the $\binom{n}{2}$ possible edges at random with equal probability for each edge,
label it $e_1$.
At time $t=2$ pick one of the remaining $\binom{n}{2}-1$ edges, again all remaining edges being equiprobable,
and denote it by $e_2$.
Continue until $M$ edges have been chosen at time $t=M$.
The graph $(V,E)$ on vertices $V = \{1, \dots, n\}$ with edges $E = \{e_1, \dots, e_M\}$ is the desired Erdös-Rényi random graph.

Using these definitions Erdös and Rényi prove that,
when increasing the number of edges $M(n)$,
the sizes of connected components undergo distinct phases leading from small sparse components and unconnected vertices
to one giant component and eventually a completely connected graph.

Most current literature and the paper we are studying uses a slightly different approach to the contruction of this random graph.
Given a set of vertices $\{1, \dots, n\}$ and an edge-probability $\p = p(n)$
we take every edge $(v_1, v_2)$ and add it to the set of edges $E$ of the random graph with probability $\p$ independently.
We call an edge $e = (v_1, v_2)$ open if $e \in E$, closed otherwise.
We denote a random object constructed this way by $\Gcal(n, \p)$ and expect a realisation of the random graph to have $\binom{n}{2}\p$ edges.
When increasing the probability $\p$ from $0$ to $1$ the resulting random graph undergoes the same so-called phase transitions
discovered by Erdös and Rényi.

While the results of the original paper hold for small and large $M(n)$,
the critical phase transistion happening around $M(n) = \frac{n}{2}$ or $\p = \frac{1}{n}$
was later discovered to be imprecise.
\fxnote{Add reference from hofstad somewhere.}
The following section will provide a more precise introduction to the different phases a random graph undergoes
with increasing number of edges.


\section{General results on component sizes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: General results on component sizes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To provide an overview of the aforementioned phases, 
which the component sizes of the Erdös-Rényi random graph pass through,
we discuss relevant results that were established previous to \cite{Aldous.1997}.

We begin with the subcritical graph, that is
$\Gcal(n, \p)$ with $\p < \frac{1}{n}$
or $\lambda = n \p < 1$.

The following theorem provides a lower bound on the size of $\Ccal_{\max}$, the largest component of $\Gcal$.
\begin{theorem}[Lower bound on largest subcritical component, {\cite[Theorem 4.4, p.125]{vanderHofstad.2016}}]
	Fix $\lambda < 1$. 
	Then, for all $a > 1/I_{\lambda}$, 
	there exists $\delta = \delta(a, \lambda)$ such that
	\begin{equation}
		\Prob( |\Ccal_{\max}| \geq a \log n ) = \BigO{n^{-\delta}},
	\end{equation}
	where 
	\begin{equation}
		I_{\lambda} = \lambda - 1 - \log(\lambda).
	\end{equation}
	is the large deviation rate function for Poisson random variables with mean $\lambda$.
\end{theorem}

The next theorem gives an upper bound for the size of $\Ccal_{\max}$.
\begin{theorem}[Upper bound on largest subcritical component, {\cite[Theorem 4.5, p.125]{vanderHofstad.2016}}]
	Fix $\lambda < 1$. 
	Then, for all $a < 1/I_{\lambda}$, 
	there exists $\delta = \delta(a, \lambda)$ such that
	\begin{equation}
	\Prob( |\Ccal_{\max}| \leq a \log n ) = \BigO{n^{-\delta}}.
	\end{equation}
\end{theorem}

Together, these theorems imply
\begin{equation}
	\frac{|\Ccal_{\max}|}{\log n} \rightarrow_p 1/I_{\lambda}.
\end{equation}

We have established that, for $n \p < 1$, the expected largest component size will be of order $\log n$.

Consider the opposite case, the supercritical graph with $\lambda > 1$. 

Denote by $\xi_\lambda$ the survival probability of a Poisson branching process with mean offspring $\lambda$.
Note that $\xi_\lambda > 0$ since $\lambda > 1$
(For an introduction into the theory of branching processes with application in random graphs, 
see \cite[Chapter 3, p.87ff.]{vanderHofstad.2016}).

Any vertex is part of a large component with probability $\xi_\lambda$, 
therefore we will expect around $n \xi_\lambda$ vertices being part of large connected components.
The following theorem now states that all of these vertices are, in fact, part of the same connected component, which we call the giant component.

\begin{theorem}[Law of large numbers for giant component, {\cite[Theorem 4.8, p.131]{vanderHofstad.2016}}]
	Fix $\lambda>1$.
	Then, for all $\nu \in (\frac{1}{2}, 1)$, there exists $\delta = \delta(\nu, \lambda)$ such that
	\begin{equation}
		\Prob\left( \left| |\Ccal_{\max}| - n \xi_\lambda \right| \geq n^{\nu}\right) = \BigO{n^{-\delta}}.
	\end{equation}
\end{theorem}

\begin{figure}[h]
	\centering
	\subfloat[$\lambda = 0.5$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_-5}}%
	\quad
	\subfloat[$\lambda = 1.5$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_5}}%
	\caption{Realizations of the Erdös-Rényi random graph on $n=1000$ vertices with different $\lambda = n \p$.}%
	\label{F: ER lambda}%
\end{figure}

Figure~\ref{F: ER lambda} provides two realizations of the random graph with different $\lambda$,
one subcritical and one supercritical.
Note how the largest connected components in the subcritical graph still consist of very few vertices
(the largest component here having 9 vertices, while $\log(1000) \approx 6.9$)
and a lot of nodes are isolated.
In contrast, the supercritical graph features a single large component 
and all other components are either drastically smaller in size or even still isolated vertices.

For $n \p < 1$ we expect many small clusters of order at most $\log n$,
for $n \p > 1$ we expect one giant component, approaching size $n$ with increasing $\p$.
But what happens around $n \p \approx 1$?
As it turns out, the emergence of the giant component occurs quite rapidly,
such that shortly after $n \p = 1$ most graphs do not have any component of order between $\frac{1}{2}\n{2}{3}$ and $\n{2}{3}$.

The following theorem provides an approximation of the time of emergence of the giant component,
seeing the random graph on $n$ vertices as a graph process,
starting at $t=0$ with $0$ edges, adding one random edge at every time step.
We would therefore expect the emergence starting around time $\binom{2}{n}\frac{1}{n} \approx \frac{1}{2}n$. 

\begin{theorem}[Emergence of the giant component, {\cite[Theorem 6.8, p.142]{Bollobas.2001}}]
	Almost every graph process\footnote{%
		We say a property $P$ is shared by almost every graph if the probability of having this property approaches $1$ as $n \rightarrow \infty$} 
	$\Gcal = (\Gcal_t)_0^n$ is such that 
	for every $t \geq t_1 = \floor{ n/2 + 2(\log n)^{1/2}\n{2}{3} }$ 
	the graph $\Gcal_t$ has a unique component of order at least $\n{2}{3}$ and the other components have at most $\frac{1}{2}\n{2}{3}$.
\end{theorem}

As it turns out, there is a so-called critical window in which the maximum component sizes are not of order $\log n$ any more 
but there is no single giant component yet.
We call a random graph $\Gcal(n, n^{-1} + t\n{-4}{3})$ critical for $t \in \Real$.
The next theorem provides a approximation of the size of the largest component in a critical random graph.

\begin{theorem}[Largest critical cluster, {\cite[Theorem 5.1, p.150]{vanderHofstad.2016}}] \label{T: largest critical cluster}
	Let $\lambda = 1 + \pp\n{-1}{3}$, with $\pp \in \Real$.
	There exists a constant $b = b(\pp)$ such that for all $\omega > 1$,
	\begin{equation}
		\Prob\left( \omega^{-1} \n{2}{3} \leq |\Ccal_{\max}| \leq \omega \n{2}{3}\right) \geq 1 - \frac{b}{\omega}.
	\end{equation}	
\end{theorem}

In this critical window, the largest component of the random graph will be of order $\n{2}{3}$ with high probability.

\begin{figure}[h]
	\centering
	\subfloat[$\pp = -3$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_-3}}%
	\quad
	\subfloat[$\pp = 0$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_1}}%
	\quad
	\subfloat[$\pp = 3$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_3}}%
	\caption{Realizations of the Erdös-Rényi random graph on $n=1000$ vertices with different $\pp$.}%
	\label{F: ER p}%
\end{figure}

Figure~\ref{F: ER p} shows realizations of the critical Erdös-Rényi random graph for different parameters $\pp$.
It is clear how the graph undergoes its transition from relatively small and simple components 
to the emergence of a single great component, which will later, i.e. for larger $\p$,
encompass more and more vertices as seen in Figure~\ref{F: ER lambda}.


But is it possible to provide a similar statement not only for the largest, but for all components in a critical random graph?
Aldous notes that previous to his paper
the convergence of the rescaled component sizes to some limit process was generally assumed to be true,
although never explicitly proven.
He therefore provides the following \emph{folk theorem},
which will be proven in more precise form in the course of this thesis.

\begin{folktheorem} \label{T: folk theorem}
	Let $\Cnt(1) \geq \Cnt(2) \geq \dots$ be the ordered component sizes of
	$\Gcal(n, n^{-1} + \pp\n{-4}{3})$ and let $\sigmant(j)$ be the surplus of the corresponding component.
	Then
	\begin{equation}
		( \n{-2}{3} ( \Cnt(j), \sigmant(j) ), \; j \geq 1 ) 
		\rightarrow_d
		( (\Ct(j), \sigmat), \; j \geq 1 )
		= ( \Ctbold, \sigmatbold ),
	\end{equation}
	as $n \rightarrow \infty$ for some limit $( \Ctbold, \sigmatbold )$
	with $0 < \Ct(j) < \infty$ and $0 \leq \sigmatbold(j) < \infty$ almost surely for each $j \geq 1$.
\end{folktheorem}



\section{Main statements of this thesis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Main statements of this thesis
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section we state the main results of this thesis,
which is a refinement of Theorem~\ref{T: largest critical cluster}.
While previously the size of largest component was only estimated to be of order $\n{2}{3}$,
the following theorem will give a limit distribution for all component sizes, downscaled by $\n{-2}{3}$.

Denote by $W$ the standard Brownian motion. 
For a fixed parameter $\pp \in \Real$ we call the process $\Wt$, defined by
\begin{equation}
	\Wt(s) := W(s) + \int_{0}^{s}(t-s)ds = W(s) + ts - \frac{1}{2}s^2,
\end{equation}
the Brownian motion with drift $t-s$ at time $s$.
The central object of our analysis will be the process $\Wt$ and its excursions above past minima.
We reflect $\Wt$ at $0$, defining the process $\Bt$ by
\begin{equation}
	\Bt(s) := \Wt(s) - \min_{u \leq s}\Wt(u)
\end{equation}
and calling it the reflected Brownian motion with drift.

\begin{figure}%
	\centering
	\subfloat[$W(s)$]{\input{figures/chapter1/fig_bm.tex}}%
	\quad
	\subfloat[$W^{\pp_1}(s)$]{\input{figures/chapter1/fig_bm_drift_pos.tex}}%
	\quad
	\subfloat[$B^{\pp_1}(s)$]{\input{figures/chapter1/fig_bm_drift_ref_pos.tex}}%
	\quad
	\subfloat[$W^{\pp_2}(s)$]{\input{figures/chapter1/fig_bm_drift_neg.tex}}%
	\quad
	\subfloat[$B^{\pp_2}(s)$]{\input{figures/chapter1/fig_bm_drift_ref_neg.tex}}%
	\caption{A sample Brownian motion, Brownian motion with drift and with reflection for $\pp_1>0$ and $\pp_2<0$.}%
	\label{F: BM}%
\end{figure}

See Figure~\ref{F: BM} for an example of a Brownian motion with drift for positive and negative $\pp$ and the corresponding reflected process.
Note that for positive $t$ the time intervals between zeroes of $\Bt$ are much longer than for negative $\pp$.
We call an excursion $\gamma$ of $\Bt$ a time interval $[l(\gamma), r(\gamma)]$ for which $\Bt(l(\gamma)) = \Bt(r(\gamma)) = 0$
and $\Bt(s) > 0$ for all $l(\gamma) < s < r(\gamma)$.
Denote by $|\gamma| = r(\gamma) - l(\gamma)$ the length of an excursion.

Additionally we define a Poisson counting process $\Nt$, 
which equips each excursion with a number of marks,
emerging with intensity $\Bt(s)$ at time $s$.
Informally speaking, the chance of encountering a mark in a time interval $\sds$ is characterized by
\begin{equation}
	\Prob( \text{Some mark emerges in} \; \sds \cond \Bt(u), u \leq s ) = \Bt(s)ds.
\end{equation}
More formally we define $\Nt$ to be the counting process for which
\begin{equation}
	\Nt(s) - \int_{0}^{s} \Bt(s)ds
\end{equation}
is a martingale.
Denote by $\mu(\gamma)$ the number of marks during an excursion $\gamma$.

We now state the main theorem of this thesis, which we will prove gradually in the following chapters.
\begin{theorem}[Main theorem] \label{T: Main}
	Let 
	$\Cnt(1) \geq \Cnt(2) \geq ... $ 
	be the ordered component sizes of 
	$\Gnt$
	and let
	$\sigmant(j)$ 
	be the surplus of the corresponding component.
	Then, as $n \rightarrow \infty$,
	\begin{equation}
	( \n{-2}{3} ( \Cnt(j), \sigmant(j) ), \; j \geq 1 ) 
	\rightarrow_d
	( (\Ct(j), \sigmat), \; j \geq 1 )
	= ( \Ctbold, \sigmatbold ),
	\end{equation}
	where the convergence 
	$\n{-2}{3} \Cntbold \rightarrow_p \Ctbold$
	holds with respect to the $\ld$ topology.
	
	The limit
	$\left( ( \Ct(j), \sigmat(j) ), \; j \geq 1 \right)$
	is distributed as the sequence
	$ \left( (|\gamma_j|, \mu(\gamma_j)), j \geq 1  \right) $
	of lengths and mark-counts of excursions of $\Bt$.
\end{theorem}
\fxfatal{ld topology must be explained or removed.}

We conclude this chapter with an overview of the remaining chapters and the structure of the proof of Theorem~\ref{T: Main}.

Chapter~\ref{C: preliminaries} will develop some preliminary theory on the function spaces $C$ and $D$,
convergence of probability measures and counting processes, which will prove useful in the coming chapters.

In Chapter~\ref{C: bf-walk} we define a way to traverse all vertices of a given graph, called the breadth-first walk $\znt$, 
that reduces the graph to a one-dimensional random walk in which component sizes are decoded as excursions above past minima.
We analyse its characteristics when applied to $\Gnt$ and discover that, after a certain rescaling, it converges in distribution to $\Wt$.

Chapter~\ref{C: surplus edges} deals with the second coordinate $\sigmant$ in Theorem~\ref{T: Main}, the surplus edges.
We describe a Poisson counting process $\nnt$ which tallies up all encountered excess edges and calculate its limit rate as $\Bt$.
The remainder of this chapter will be spent proving that this convergence of rates suffices to declare the convergence of the joint distribution of
the rescaled breadth-first walk and this counting process to $\Wt$ and $\Nt$.

It remains to be proven that not only does the rescaled random walk converge in distribution to the Brownian motion with drift,
but that the convergence of component sizes to lengths of excursions of $\Bt$ in distribution follows as well.
In Chapter~\ref{C: convergence} we first prove that this does indeed hold if we must not expect any large components to "wander off to infinity" as $n \rightarrow \infty$ and subsequently that, with high probability, this problem does not arise in $\Gnt$.
This completes the proof of Theorem~\ref{T: Main}.

Lastly, Chapter~\ref{C: outlook} provides an overview over the remaining statements of Aldous paper,
which contains a non-uniform version of Theorem~\ref{T: Main} and the multiplicative coalescent, 
a process describing the joining of components to form larger components as the parameter $\pp$ grows.


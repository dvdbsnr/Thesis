% Chapter 1: Introduction
% Contains:
%   An introduction to random graph theory
%   Basic results on the size of random graph components
%   Basic results on the critical window
%   The main theorem:
%      Motivation
%      The Brownian motion
%      Complete statement
%   Overview of coming proof

\chapter{Introduction}
\fxnote{Update title.}

The study of randomly generated graphs started in 1959,
when Paul Erd\H{o}s and Alfréd Rényis paper "On random graphs", \cite{Erdos.1959},
and Edgar Gilberts paper "Random graphs", \cite{Gilbert.1959},
introduced what is now known as the \emph{Erd\H{o}s-Rényi model} of random graphs.

Starting with the original papers,
the examination of sizes of connected components in such graphs was of great interest.
David Aldous 1997 paper "Brownian excursions, critical random graphs and the multiplicative coalescent", \cite{Aldous.1997},
which provides the basis for this thesis,
examines component sizes in the so-called critical Erd\H{o}s-Rényi random graph as the number of vertices $n$ grows to infinity.

This thesis will provide a strict proof of one of the the main results of this paper.
If no other reference is given, each result (or an equivalent thereof) can be found in Chapters 1 and 2 of \cite{Aldous.1997}.


\section{The Erd\H{o}s-Rényi random graph}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: The Erd\H{o}s-Rényi random graph
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In their paper, Erd\H{o}s and Rényi proposed a model of random graph that is now known as the Erd\H{o}s-Rényi random graph.
There are several ways to construct this random graph which we will briefly introduce,
starting with the historic models used in this first paper 
and continuing with the equivalent model which provides the basis for Aldous' paper and consequently this thesis.

We denote by $G_{n,M}$ the set of graphs on $n$ vertices with $M$ edges that are
\begin{enumerate}
	\item undirected,
	\item without slings, i.e. there is no edge $(v,v)$ for some vertex $v$,
	\item without parallel edges, i.e. there can be at most one edge $(v_1, v_2)$ for each pair of vertices.
\end{enumerate}
A graph in $G_{n,M}$ can be constructed by choosing $M$ out of the $\binom{n}{2}$ possible edges between the vertices,
which leads to a total number of graphs
\begin{equation}
	|G_{n,M}| = \binom{\binom{n}{2}}{M}.
\end{equation}
The Erd\H{o}s-Rényi random graph $\Gcal(n, M)$ is now obtained by choosing one element of $G_{n,M}$ at random
with equal probability for each graph, where the number of edges is usually dependent on the number of vertices, $M = M(n)$.

An equivalent definition provides the following process:
Starting with a graph on $n$ vertices with $0$ edges at time $t=1$, 
pick one of the $\binom{n}{2}$ possible edges at random with equal probability for each edge,
label it $e_1$.
At time $t=2$ pick one of the remaining $\binom{n}{2}-1$ edges, again all remaining edges being equiprobable,
and denote it by $e_2$.
Continue until $M$ edges have been chosen at time $t=M$.
The graph $(V,E)$ on vertices $V = \{1, \dots, n\}$ with edges $E = \{e_1, \dots, e_M\}$ is the desired Erd\H{o}s-Rényi random graph.

Using these definitions Erd\H{o}s and Rényi prove that,
when increasing the number of edges $M(n)$,
the sizes of connected components undergo distinct phases leading from small sparse components and unconnected vertices
to one giant component and eventually a completely connected graph.

Most current literature and the paper we are studying uses a slightly different approach to the construction of this random graph.
Given a set of vertices $\{1, \dots, n\}$ and an edge-probability $\p = p(n)$
we take every edge $(v_1, v_2)$ and add it to the set of edges $E$ of the random graph with probability $\p$ independently.
We call an edge $e = (v_1, v_2)$ open if $e \in E$, closed otherwise.
We denote a random object constructed this way by $\Gcal(n, \p)$\label{I: gnt} and expect a realisation of the random graph to have $\binom{n}{2}\p$ edges.
When increasing the probability $\p$ from $0$ to $1$ the resulting random graph undergoes the same so-called phase transitions
discovered by Erd\H{o}s and Rényi.

These phase transitions include a sudden dramatic increase in average component size happening around $M(n) = \frac{n}{2}$ or $\p = \frac{1}{n}$
which we study in this thesis.
The following section will provide a more precise introduction to the different phases a random graph undergoes
with increasing number of edges.


\section{General results on component sizes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: General results on component sizes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To provide an overview of the aforementioned phases
which the component sizes of the Erd\H{o}s-Rényi random graph pass through,
we discuss relevant results that were established previous to \cite{Aldous.1997}.

We begin with the subcritical graph, that is
$\Gcal(n, \p)$ with $\p < \frac{1}{n}$
or $\lambda = n \p < 1$.
The following theorem provides a lower bound on the size of $\Ccal_{\max}$, the largest component of $\Gcal$.
\begin{theorem}[Lower bound on largest subcritical component, {\cite[Theorem 4.4, p.125]{vanderHofstad.2016}}]
	Fix $\lambda < 1$. 
	Then, for all $a > 1/I_{\lambda}$, 
	there exists $\delta = \delta(a, \lambda)$ such that
	\begin{equation}
		\Prob( |\Ccal_{\max}| \geq a \log n ) = \BigO{n^{-\delta}},
	\end{equation}
	where 
	\begin{equation}
		I_{\lambda} = \lambda - 1 - \log(\lambda).
	\end{equation}
	is the large deviation rate function for Poisson random variables with mean $\lambda$.
\end{theorem}
The next theorem gives an upper bound for the size of $\Ccal_{\max}$.
\begin{theorem}[Upper bound on largest subcritical component, {\cite[Theorem 4.5, p.125]{vanderHofstad.2016}}]
	Fix $\lambda < 1$. 
	Then, for all $a < 1/I_{\lambda}$, 
	there exists $\delta = \delta(a, \lambda)$ such that
	\begin{equation}
	\Prob( |\Ccal_{\max}| \leq a \log n ) = \BigO{n^{-\delta}}.
	\end{equation}
\end{theorem}
Together, these theorems imply
\begin{equation}
	\frac{|\Ccal_{\max}|}{\log n} \rightarrow_p 1/I_{\lambda}.
\end{equation}
and therefore the expected largest component size will be of order $\log n$.

\bigskip

Consider the opposite case, the supercritical graph with $\lambda > 1$.
Denote by $\xi_\lambda$ the survival probability of a Poisson branching process with mean offspring $\lambda$.
Note that $\xi_\lambda > 0$ since $\lambda > 1$
(For an introduction into the theory of branching processes with application in random graphs, 
see \cite[Chapter 3, p.87ff.]{vanderHofstad.2016}).
Any vertex is part of a large component with probability $\xi_\lambda$, 
therefore we will expect around $n \xi_\lambda$ vertices being part of large connected components.
The following theorem now states that all of these vertices are, in fact, part of the same connected component, which we call the giant component.

\begin{theorem}[Law of large numbers for giant component, {\cite[Theorem 4.8, p.131]{vanderHofstad.2016}}]
	Fix $\lambda>1$.
	Then, for all $\nu \in (\frac{1}{2}, 1)$, there exists $\delta = \delta(\nu, \lambda)$ such that
	\begin{equation}
		\Prob\left( \left| |\Ccal_{\max}| - n \xi_\lambda \right| \geq n^{\nu}\right) = \BigO{n^{-\delta}}.
	\end{equation}
\end{theorem}

\begin{figure}[h]
	\centering
	\subfloat[$\lambda = 0.5$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_-5}}%
	\quad
	\subfloat[$\lambda = 1.5$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_5}}%
	\caption{Realizations of the Erd\H{o}s-Rényi random graph on $n=1000$ vertices with varying $\lambda = n \p$.}%
	\label{F: ER lambda}%
\end{figure}

Figure~\ref{F: ER lambda} provides two realizations of the random graph with different $\lambda$,
one subcritical and one supercritical.
Note how the largest connected components in the subcritical graph still consist of very few vertices
(the largest component here having 9 vertices, while $\log(1000) \approx 6.9$)
and how a lot of nodes are isolated.
In contrast, the supercritical graph features a single large component 
and all other components are either drastically smaller in size or even still isolated vertices.

\bigskip

For $n \p < 1$ we expect many small clusters of order at most $\log n$,
for $n \p > 1$ we expect one giant component, approaching size $n$ with increasing $\p$.
But what happens around $n \p \approx 1$?
As it turns out, the emergence of the giant component occurs quite rapidly,
such that shortly after $n \p = 1$ most graphs do not have any component of order between $\frac{1}{2}\n{2}{3}$ and $\n{2}{3}$.

The following theorem provides an approximation of the time of emergence of the giant component,
seeing the random graph on $n$ vertices as a graph process,
starting at $t=0$ with $0$ edges, adding one random edge at every time step.
We would therefore expect the emergence starting around time $\binom{2}{n}\frac{1}{n} \approx \frac{1}{2}n$.
We say a property $P$ is shared by almost every graph if the probability of having this property approaches $1$ as $n \rightarrow \infty$.

\begin{theorem}[Emergence of the giant component, {\cite[Theorem 6.8, p.142]{Bollobas.2001}}]
	Almost every graph process
	$\Gcal = (\Gcal_t)_0^n$ is such that 
	for every $t \geq t_1 = \floor{ n/2 + 2(\log n)^{1/2}\n{2}{3} }$ 
	the graph $\Gcal_t$ has a unique component of order at least $\n{2}{3}$ and the other components have at most $\frac{1}{2}\n{2}{3}$.
\end{theorem}

As it turns out, there is a so-called critical window in which the maximum component sizes are not of order $\log n$ any more 
but there is no single giant component yet.
We call a random graph $\Gcal(n, n^{-1} + \pp\n{-4}{3})$ critical for $\pp \in \Real$.\label{I: pp}
The next theorem provides a approximation of the size of the largest component in a critical random graph.

\begin{theorem}[Largest critical cluster, {\cite[Theorem 5.1, p.150]{vanderHofstad.2016}}] \label{T: largest critical cluster}
	Let $\lambda = 1 + \pp\n{-1}{3}$, with $\pp \in \Real$.
	There exists a constant $b = b(\pp)$ such that for all $\omega > 1$,
	\begin{equation}
		\Prob\left( \omega^{-1} \n{2}{3} \leq |\Ccal_{\max}| \leq \omega \n{2}{3}\right) \geq 1 - \frac{b}{\omega}.
	\end{equation}	
\end{theorem}

In this critical window, the largest component of the random graph will be of order $\n{2}{3}$ with high probability.

\begin{figure}[h]
	\centering
	\subfloat[$\pp = -3$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_-3}}%
	\quad
	\subfloat[$\pp = 0$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_1}}%
	\quad
	\subfloat[$\pp = 3$]{\includegraphics[page=1,width=.31\textwidth]{figures/chapter1/ER_1000_3}}%
	\caption{Realizations of the Erd\H{o}s-Rényi random graph on $n=1000$ vertices with varying $\pp$.}%
	\label{F: ER p}%
\end{figure}

Figure~\ref{F: ER p} shows realizations of the critical Erd\H{o}s-Rényi random graph for different parameters $\pp$.
It is evident how the graph undergoes its transition from relatively small and simple components 
to the emergence of a single great component, which will later, i.e. for larger $\p$,
encompass more and more vertices as seen in Figure~\ref{F: ER lambda}.

\bigskip

But is it possible to provide a similar statement not only for the largest, but for all components in a critical random graph?
Aldous notes that previous to his paper
the convergence of the rescaled component sizes to some limit process was generally assumed to be true,
although never explicitly proven.
He therefore provides the following folk theorem,
which will be proven along with a more precise version in the course of this thesis.

For a connected component we define the number of surplus edges or the surplus by
\begin{equation}
	\text{surplus} = \text{number of edges} - \text{number of vertices} + 1.
\end{equation}
The surplus gives the maximum number of edges we can remove from the component so that it stays connected.
A component with a surplus of zero is a tree.

\begin{folktheorem} \label{T: folk theorem}
	Let $\Cnt(1) \geq \Cnt(2) \geq \dots$ be the ordered component sizes of
	$\Gcal(n, n^{-1} + \pp\n{-4}{3})$ and let $\sigmant(j)$ be the surplus of the corresponding component.
	Then
	\begin{equation}
		( \n{-2}{3} ( \Cnt(j), \sigmant(j) ), \; j \geq 1 ) 
		\rightarrow_d
		( (\Ct(j), \sigmat(j)), \; j \geq 1 )
		= ( \Ctbold, \sigmatbold ),
	\end{equation}
	as $n \rightarrow \infty$ for some limit $( \Ctbold, \sigmatbold )$
	with $0 < \Ct(j) < \infty$ and $0 \leq \sigmat(j) < \infty$ almost surely for each $j \geq 1$.
\end{folktheorem}

The convergence is to hold with respect to the product topology, 
where $\xn \rightarrow \x$ holds for $\xn = (x^{(n)}_1, x^{(n)}_2, \dots)$ and $\x = (x_1, x_2, \dots)$
if for all $k \in \Nat$
\begin{equation}
	(x^{(n)}_1, \dots, x^{(n)}_k) \rightarrow (x_1, \dots,  x_k)
\end{equation}
by $x^{(n)}_i \rightarrow x_i$ for all $1 \leq i \leq k$ as $n \rightarrow \infty$.
Note that in our theorem the $x^{(n)}_i = ( \n{-2}{3} \Cnt(i), \n{-2}{3} \sigmant(i))$ and $x_i = (\Ct(i), \sigmat(i))$ are pairs of values themselves,
so for $x^{(n)}_i \rightarrow x_i$ to hold we require 
$\n{-2}{3}  \Cnt(i) \rightarrow \Ct(i)$ and $\n{-2}{3} \sigmant(i) \rightarrow \sigmat(i)$ 
in $\Real$ as $n \rightarrow \infty$.


\section{Main statements of this thesis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: Main statements of this thesis
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section we state the main results of this thesis,
which is a refinement of Folk Theorem~\ref{T: folk theorem}.
We now identify the distribution of the limit vector precisely and state a stricter form of convergence of component sizes.

Denote by $W$ the standard Brownian motion on $\Rplus$.\label{I: bm} 
For a fixed parameter $\pp \in \Real$ we call the process $\Wt$, defined by
\begin{equation} \label{D: Wt}
	\Wt(s) := W(s) + \int_{0}^{s}(\pp - u)du = W(s) + \pp s - \frac{1}{2}s^2,
\end{equation}
the Brownian motion with drift $\pp -s$ at time $s$.
The central object of our analysis will be the process $\Wt$ and its excursions above past minima.
We reflect $\Wt$ at the x-axis to define the process $\Bt$ by
\begin{equation} \label{D: Bt}
	\Bt(s) := \Wt(s) - \min_{u \leq s}\Wt(u).
\end{equation}
We call $\Bt$ the reflected Brownian motion with drift.

\begin{figure}[h]%
	\centering
	\subfloat[$W(s)$]{\input{figures/chapter1/fig_bm.tex}}%
	\quad
	\subfloat[$W^{\pp_1}(s)$]{\input{figures/chapter1/fig_bm_drift_pos.tex}}%
	\quad
	\subfloat[$B^{\pp_1}(s)$]{\input{figures/chapter1/fig_bm_drift_ref_pos.tex}}%
	\quad
	\subfloat[$W^{\pp_2}(s)$]{\input{figures/chapter1/fig_bm_drift_neg.tex}}%
	\quad
	\subfloat[$B^{\pp_2}(s)$]{\input{figures/chapter1/fig_bm_drift_ref_neg.tex}}%
	\caption{A sample Brownian motion, Brownian motion with drift and with reflection for $\pp_1>0$ and $\pp_2<0$.}%
	\label{F: BM}%
\end{figure}

See Figure~\ref{F: BM} for an example of a Brownian motion with drift for positive and negative $\pp$ and the corresponding reflected process.
Note that for positive $\pp$ the time intervals between zeroes of $\Bt$ are much longer than for negative $\pp$.
We call an excursion $\gamma$ of $\Bt$ a time interval $[l(\gamma), r(\gamma)]$ for which $\Bt(l(\gamma)) = \Bt(r(\gamma)) = 0$
and $\Bt(s) > 0$ for all $l(\gamma) < s < r(\gamma)$. \label{I: gamma}
Denote by $|\gamma| = r(\gamma) - l(\gamma)$ the length of an excursion. \label{I: rgammalgamma}

Additionally we define a Poisson counting process $\Nt$, \label{I: nt} 
which equips each excursion with a number of marks,
emerging with intensity $\Bt(s)$ at time $s$.
Informally speaking, the chance of encountering a mark in a time interval $\sds$ is characterized by
\begin{equation}
	\Prob( \text{Some mark emerges in} \; \sds \cond \Bt(u), u \leq s ) = \Bt(s)ds.
\end{equation}
More formally we define $\Nt$ to be the counting process for which
\begin{equation}
	\Nt(s) - \int_{0}^{s} \Bt(u)du
\end{equation}
is a martingale.
Denote by $\mu(\gamma)$ the number of marks during an excursion $\gamma$. \label{I: mugamma}

The folk theorem states a convergence of both component sizes and surplus edges in the product topology.
We here provide additional information on the convergence of component sizes.
Let
\begin{equation} \label{D: ld}
	\ld := \{ \x = (x_1, x_2, \dots) \cond x_1 \geq x_2 \geq \dots \geq 0, \; \sideset{}{_i}\sum x^2_i < \infty \}
\end{equation}
and define the natural metric on $\ld$ by
\begin{equation}
	d_2(\boldsymbol{x},\boldsymbol{y}) = \sqrt{\sideset{}{_i}\sum (x_i - y_i)^2}.
\end{equation}
For a finite sequence like $\Cntbold$, the ordered component sizes of a graph on $n$ vertices, we append zeroes in order to regard it as an element on $\ld$.


We now state the main theorem of this thesis, which we will prove gradually in the following chapters.
\begin{theorem}[Main theorem] \label{T: Main}
	Let $\Cnt(1) \geq \Cnt(2) \geq ... $ be the ordered component sizes of $\Gnt$
	and let $\sigmant(j)$ be the surplus of the corresponding component.
	Then, as $n \rightarrow \infty$,
	\begin{enumerate}
		\item the convergence
		\begin{equation}
		( \n{-2}{3} ( \Cnt(j), \sigmant(j) ), \; j \geq 1 ) 
		\rightarrow_d
		( \Ctbold, \sigmatbold ),
		\end{equation}
		holds with respect to the product topology,
		
		\item the convergence $\n{-2}{3} \Cntbold \rightarrow_p \Ctbold$
		holds with respect to the $\ld$ topology and
		
		\item the limit
		$( \Ctbold, \sigmatbold ) = \left( ( \Ct(j), \sigmat(j) ), \; j \geq 1 \right)$
		is distributed as the sequence of lengths and mark-counts
		$ \left( (|\gamma_j|, \mu(\gamma_j)), j \geq 1  \right) $
		of excursions of $\Bt$.
	\end{enumerate}
\end{theorem}
\begin{note}
	The Folk Theorem~\ref{T: folk theorem} is contained in the first statement of Theorem~\ref{T: Main}.
\end{note}


We conclude this chapter with an overview of the remaining chapters and the structure of the proof of Theorem~\ref{T: Main}.

Chapter~\ref{C: preliminaries} will introduce some preliminary theory on convergence of probability measures,
the space of \cadlag~functions $\DT$, counting processes and Brownian motion.

In Chapter~\ref{C: bf-walk} we define a way to traverse all vertices of a given graph, called the breadth-first walk $Z(s)$, 
that reduces the graph to a one-dimensional random walk in which component sizes are decoded as excursions above past minima.
We analyse its characteristics when applied to $\Gnt$ and discover that it converges in distribution to $\Wt$ after rescaling.

Chapter~\ref{C: surplus edges} deals with the second coordinate $\sigmant$ in Theorem~\ref{T: Main}, the surplus edges.
We describe a Poisson counting process $\nnt$ which tallies up all encountered excess edges and calculate its limit rate as $\Bt$.
The remainder of this chapter will be spent proving that this convergence of rates suffices to declare the convergence of the joint distribution of
the rescaled breadth-first walk and this counting process to $\Wt$ and $\Nt$.

The final proof of Theorem~\ref{T: Main} happens in Chapter~\ref{C: convergence}.
We show that the convergence in distribution of the rescaled breadth-first walk to the Brownian motion with drift
indeed implies convergence of excursions of certain length on finite intervals.
A problem that remains is the possibility of large excursions "wandering off to infinity", 
which in Aldous' paper is solved by reference to existing random graphs results.
We prove that we do not need to worry about these excursions or the total weight of smaller excursions
independently of literature on random graphs. 
We subsequently show that the convergence of component sizes and surplus edges holds in the product topology 
and the former additionally in the $\ld$~topology.

Aldous' paper provides a similar result for a nonuniform graph model where vertices have distinct sizes
and large vertices are more likely to connect to other vertices.
We introduce this model and the statement of its equivalent to Theorem~\ref{T: Main} briefly in Chapter~\ref{C: nonuniform graph}.

Lastly, Chapter~\ref{C: outlook} provides an overview over the remaining results of Aldous' paper,
which feature the multiplicative coalescent, a Markov process on $\ld$ that describes the behaviour of component sizes for fixed $n$ and variable $\pp$.
